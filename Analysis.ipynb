{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8cgGp5xAMyn0Nyne10Zb/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/runnithan03/Dissertation/blob/main/Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#complete pipeline to predict rugby match outcomes and point margins using historical data and machine learning techniques."
      ],
      "metadata": {
        "id": "wxABAjmaovop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collection\n"
      ],
      "metadata": {
        "id": "XZWJYFsmlSuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "K0ZQdLHWlHsu",
        "outputId": "d998a241-45fb-4db0-e12c-80beb68da117"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_your_sports_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e126d2eb7775>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load dataset (replace with the actual dataset path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path_to_your_sports_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display first few rows to understand the data structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_sports_dataset.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset (replace with the actual dataset path)\n",
        "df = pd.read_csv('rugby_dataset.csv')\n",
        "\n",
        "# Display first few rows to understand the data structure\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing and Coding Section"
      ],
      "metadata": {
        "id": "AdGhCM14lbYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/kaggle/input/international-rugby-union-results-from-18712022/results.csv')\n",
        "wc_games = pd.read_excel('wc_results.xlsx')\n",
        "N = len(wc_games)\n",
        "\n",
        "# Concatenate the datasets\n",
        "df = pd.concat([df, wc_games], axis=0)\n",
        "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
        "\n",
        "# Only include data from 1995 onwards\n",
        "df = df[df['date'] > '1995-01-01']\n",
        "\n",
        "def determine_winner_and_loser(row):\n",
        "    # Function which adds winner and loser columns to the dataframe\n",
        "    if row['home_score'] > row['away_score']:\n",
        "        winner = row['home_team']\n",
        "        loser = row['away_team']\n",
        "    elif row['home_score'] < row['away_score']:\n",
        "        winner = row['away_team']\n",
        "        loser = row['home_team']\n",
        "    else:\n",
        "        winner = 'Draw'\n",
        "        loser = 'Draw'\n",
        "    return winner, loser\n",
        "\n",
        "def calculate_team_form(df, team_name, current_row_index, n_games):\n",
        "    # Function which calculates form of each team over the last N games\n",
        "    team_form = []\n",
        "    games_b = df.iloc[:current_row_index]\n",
        "\n",
        "    for index in range(len(games_b)-1, -1, -1):\n",
        "        row1 = games_b.iloc[index]\n",
        "        if row1['home_team'] == team_name or row1['away_team'] == team_name:\n",
        "            if row1['winner'] == 'Draw':\n",
        "                team_form.append(0.5)\n",
        "            elif row1['winner'] == team_name:\n",
        "                team_form.append(1)\n",
        "            else:\n",
        "                team_form.append(0)\n",
        "\n",
        "    return sum(team_form[:n_games])\n",
        "\n",
        "# Apply the function to create new 'winner' and 'loser' columns\n",
        "df[['winner', 'loser']] = df.apply(determine_winner_and_loser, axis=1).apply(pd.Series)\n",
        "\n",
        "# Initialize columns to store the live ranking points of both teams\n",
        "df['ranking_points_home'] = 0\n",
        "df['ranking_points_away'] = 0\n",
        "\n",
        "# Add a column representing the margin in favour of the 'home' team\n",
        "df['margin'] = df['home_score'] - df['away_score']\n",
        "\n",
        "# Add a column which specifies match result as either home_win, away_win, or draw\n",
        "df['result'] = df['margin'].apply(lambda x: 'home_win' if x > 0 else ('away_win' if x < 0 else 'draw'))\n",
        "\n",
        "# Initialize rankings dictionary, all teams start on 80\n",
        "ranking_points = {'Scotland': 80, 'England': 80, 'Wales': 80, 'Italy': 80, 'France': 80, 'Ireland': 80,\n",
        "                  'New Zealand': 80, 'Argentina': 80, 'South Africa': 80, 'Australia': 80}\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    # For each match in the dataframe, add the live rankings of both teams tracked in the dictionary ranking_points\n",
        "    home_team = row['home_team']\n",
        "    away_team = row['away_team']\n",
        "\n",
        "    # Update ranking_points_home and ranking_points_away\n",
        "    df.at[i, 'ranking_points_home'] = ranking_points[home_team]\n",
        "    df.at[i, 'ranking_points_away'] = ranking_points[away_team]\n",
        "\n",
        "    # Adjust points for neutral venues\n",
        "    if row['neutral']:\n",
        "        home_points = ranking_points[home_team]\n",
        "    else:\n",
        "        home_points = ranking_points[home_team] + 3\n",
        "\n",
        "    away_points = ranking_points[away_team]\n",
        "    gap = home_points - away_points\n",
        "    gap = max(min(gap, 10), -10)  # Cap the gap between -10 and 10\n",
        "\n",
        "    # Calculate core points adjustment based on match result\n",
        "    if row['winner'] == 'Draw':\n",
        "        core = gap * 0.1\n",
        "    elif row['winner'] == home_team:\n",
        "        core = 1 - (gap * 0.1)\n",
        "    else:\n",
        "        core = 1 + (gap * 0.1)\n",
        "\n",
        "    # Apply additional modifiers\n",
        "    if abs(row['home_score'] - row['away_score']) > 15:\n",
        "        core *= 1.5\n",
        "    if row['world_cup']:\n",
        "        core *= 2\n",
        "\n",
        "    # Adjust rankings based on match result\n",
        "    if row['winner'] != 'Draw':\n",
        "        ranking_points[row['winner']] += core\n",
        "        ranking_points[row['loser']] -= core\n",
        "    else:\n",
        "        ranking_points[home_team] -= core\n",
        "        ranking_points[away_team] += core\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Calculate team forms for each match\n",
        "for idx, row in df.iterrows():\n",
        "    df.at[idx, 'home_form'] = calculate_team_form(df, row['home_team'], idx, n_games=5)\n",
        "    df.at[idx, 'away_form'] = calculate_team_form(df, row['away_team'], idx, n_games=5)\n"
      ],
      "metadata": {
        "id": "QG19fr_8ldGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering and Data Splitting"
      ],
      "metadata": {
        "id": "4X2deXWylfA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider games from 1996 onwards so the rankings have had time to calibrate\n",
        "data = df.copy()\n",
        "data = data[data['date'] > '1996-01-01']\n",
        "\n",
        "# Encode the 'neutral' and 'world_cup' columns as binary indicator variables\n",
        "data['neutral'] = data['neutral'].astype(int)\n",
        "data['world_cup'] = data['world_cup'].astype(int)\n",
        "\n",
        "# Split into train and test datasets, using 01/01/2017 as the cut-off point\n",
        "train_data = data[data['date'] < '2017-01-01']\n",
        "test_data = data[data['date'] >= '2017-01-01']\n",
        "\n",
        "# Define features and target variables for training and testing\n",
        "X_train = train_data[['neutral', 'world_cup', 'ranking_points_home', 'ranking_points_away', 'home_form', 'away_form']]\n",
        "y_train = train_data['margin']\n",
        "X_test = test_data[['neutral', 'world_cup', 'ranking_points_home', 'ranking_points_away', 'home_form', 'away_form']]\n",
        "y_test = test_data['margin']\n"
      ],
      "metadata": {
        "id": "KobDNdJplhGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Scaling"
      ],
      "metadata": {
        "id": "6dyRAvIQlliT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and test data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "AC8x2U20lmt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building and Evaluation"
      ],
      "metadata": {
        "id": "fdRgO3GPloOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest Regressor': RandomForestRegressor(),\n",
        "    'Support Vector Regressor': SVR()\n",
        "}\n",
        "\n",
        "# Iterate over models to train, predict, and evaluate\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"R-squared (R2): {r2:.2f}\")\n",
        "    print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "Q7yqeHl2lq9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Match Winner using Classification Models"
      ],
      "metadata": {
        "id": "TzSZIaIMlxSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Redefine the target variables for classification (match result)\n",
        "y_train_class = train_data['result']\n",
        "y_test_class = test_data['result']\n",
        "\n",
        "# Initialize and fit the RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_scaled, y_train_class)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_class = clf.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "classification_rep = classification_report(y_test_class, y_pred_class)\n",
        "\n",
        "# Print results\n",
        "print('Random Forest Results')\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "8zljc_a_lyuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Classifier"
      ],
      "metadata": {
        "id": "YM_NLv8PoZlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize and fit the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train_scaled, y_train_class)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_logreg = logreg.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "accuracy_logreg = accuracy_score(y_test_class, y_pred_logreg)\n",
        "classification_rep_logreg = classification_report(y_test_class, y_pred_logreg)\n",
        "\n",
        "# Print results for Logistic Regression\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy_logreg:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_logreg)\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "65-0eYydobNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "iMCTI0zPofQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and fit a Decision Tree classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train_scaled, y_train_class)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_decision_tree = decision_tree.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "accuracy_decision_tree = accuracy_score(y_test_class, y_pred_decision_tree)\n",
        "classification_rep_decision_tree = classification_report(y_test_class, y_pred_decision_tree)\n",
        "\n",
        "# Print results for Decision Tree\n",
        "print(\"Decision Tree Results:\")\n",
        "print(f\"Accuracy: {accuracy_decision_tree:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_decision_tree)\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "eVtp6iymogxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Matches"
      ],
      "metadata": {
        "id": "kOUt1YAMohlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on all data pre-RWC 2023 and test on the RWC games\n",
        "X_train_wc = data[['neutral', 'world_cup', 'ranking_points_home', 'ranking_points_away', 'home_form', 'away_form']]\n",
        "y_train_wc = data['result']\n",
        "X_test_wc = wc_games[['neutral', 'world_cup', 'ranking_points_home', 'ranking_points_away', 'home_form', 'away_form']]\n",
        "y_test_wc = wc_games['result']\n",
        "\n",
        "# Scale the data\n",
        "X_train_wc_scaled = scaler.fit_transform(X_train_wc)\n",
        "X_test_wc_scaled = scaler.transform(X_test_wc)\n",
        "\n",
        "# Initialize and fit a Logistic Regression classifier\n",
        "logreg_wc = LogisticRegression(random_state=42)\n",
        "logreg_wc.fit(X_train_wc_scaled, y_train_wc)\n",
        "\n",
        "# Predict on the World Cup test data\n",
        "y_pred_wc = logreg_wc.predict(X_test_wc_scaled)\n",
        "\n",
        "# Evaluate the Logistic Regression model on World Cup games\n",
        "accuracy_wc = accuracy_score(y_test_wc, y_pred_wc)\n",
        "classification_rep_wc = classification_report(y_test_wc, y_pred_wc)\n",
        "\n",
        "# Print results for World Cup prediction\n",
        "print(\"Logistic Regression Results on World Cup Games:\")\n",
        "print(f\"Accuracy: {accuracy_wc:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_wc)\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "id": "TVQHwTv-oqT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}