{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmhMB4xCxkaEL7GDwfY1/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/runnithan03/Dissertation/blob/main/Dissertation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso Regression"
      ],
      "metadata": {
        "id": "RVEKc4kI6uM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu7QC7pp6g8e",
        "outputId": "947622d3-55d7-43ed-89c9-e245f94cd77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating sample dataset...\n",
            "Shapes of X_train and y_train:\n",
            "(100, 20)\n",
            "(100,)\n",
            "Fitting Lasso (L1) Regularization model...\n",
            "Lasso model coefficients: [[ 0.          0.          0.          0.          0.28613678  0.\n",
            "  -2.11185444  0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.20170223  0.          3.20555137\n",
            "   0.          0.        ]]\n",
            "Lasso model accuracy on training data: 0.99\n",
            "Fitting Ridge (L2) Regularization model...\n",
            "Ridge model coefficients: [[ 0.53796691  0.22762154 -0.56878911 -0.19871216  0.56092924  0.12798941\n",
            "  -1.06670917 -0.07043501  0.15573116 -0.11013136 -0.75531367  0.32347209\n",
            "  -0.83402903 -0.33845405 -0.03755675  0.41659081  0.20915689  0.97093934\n",
            "   0.67589751 -0.84130427]]\n",
            "Ridge model accuracy on training data: 1.0\n",
            "Script completed.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Generating sample dataset...\")\n",
        "\n",
        "# Generate a sample dataset\n",
        "X_train, y_train = make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
        "\n",
        "# Print the shapes of X_train and y_train to verify\n",
        "print(\"Shapes of X_train and y_train:\")\n",
        "print(X_train.shape)  # Should output (100, 20)\n",
        "print(y_train.shape)  # Should output (100,)\n",
        "\n",
        "print(\"Fitting Lasso (L1) Regularization model...\")\n",
        "\n",
        "# Lasso (L1) Regularization\n",
        "model_lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=10000).fit(X_train, y_train)\n",
        "print(\"Lasso model coefficients:\", model_lasso.coef_)\n",
        "print(\"Lasso model accuracy on training data:\", accuracy_score(y_train, model_lasso.predict(X_train)))\n",
        "\n",
        "print(\"Fitting Ridge (L2) Regularization model...\")\n",
        "\n",
        "# Ridge (L2) Regularization\n",
        "model_ridge = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=10000).fit(X_train, y_train)\n",
        "print(\"Ridge model coefficients:\", model_ridge.coef_)\n",
        "print(\"Ridge model accuracy on training data:\", accuracy_score(y_train, model_ridge.predict(X_train)))\n",
        "\n",
        "print(\"Script completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch"
      ],
      "metadata": {
        "id": "rscPwC7l62Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 1. Basic Tensor Operations\n",
        "# Create a tensor\n",
        "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float)\n",
        "print(f\"Tensor x:\\n{x}\")\n",
        "\n",
        "# Create a tensor filled with zeros\n",
        "zeros = torch.zeros((2, 3))\n",
        "print(f\"Zeros tensor:\\n{zeros}\")\n",
        "\n",
        "# Create a random tensor\n",
        "random_tensor = torch.rand((2, 2))\n",
        "print(f\"Random tensor:\\n{random_tensor}\")\n",
        "\n",
        "# Element-wise addition\n",
        "y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float)\n",
        "result_add = x + y\n",
        "print(f\"Element-wise addition result:\\n{result_add}\")\n",
        "\n",
        "# Matrix multiplication\n",
        "result_mul = torch.matmul(x, y)\n",
        "print(f\"Matrix multiplication result:\\n{result_mul}\")\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "x_gpu = x.to(device)\n",
        "print(f\"Tensor x on {device}:\\n{x_gpu}\")\n",
        "\n",
        "# 2. Define a Simple Neural Network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(128, 64)   # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(64, 10)    # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and move it to the appropriate device\n",
        "model = SimpleNN().to(device)\n",
        "\n",
        "# 3. Prepare Data - Using the MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 4. Set Up Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 5. Training the Neural Network\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        # Flatten the input images\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 6. Evaluate the Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # No need to calculate gradients during evaluation\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 7. Save the Model\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "print(\"Model saved to 'model.pth'.\")\n",
        "\n",
        "# 8. Load the Model\n",
        "#loaded_model = SimpleNN()\n",
        "#loaded_model.load_state_dict(torch.load('model.pth'))\n",
        "#loaded_model = loaded_model.to(device)\n",
        "#print(\"Model loaded and ready for inference.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO5T8eRU6pHK",
        "outputId": "1304343b-a082-4562-e62e-9b87f3f0fba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Tensor x:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Zeros tensor:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Random tensor:\n",
            "tensor([[0.3011, 0.3242],\n",
            "        [0.1040, 0.5545]])\n",
            "Element-wise addition result:\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]])\n",
            "Matrix multiplication result:\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "Tensor x on cpu:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 15739736.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 488639.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4367422.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2448024.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1, Loss: 0.41992934463994464\n",
            "Epoch 2, Loss: 0.17773972845463548\n",
            "Epoch 3, Loss: 0.12797877673051758\n",
            "Epoch 4, Loss: 0.10175308126555101\n",
            "Epoch 5, Loss: 0.08649959495571106\n",
            "Training complete.\n",
            "Accuracy on the test set: 96.91%\n",
            "Model saved to 'model.pth'.\n",
            "Model loaded and ready for inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d1fe061ac674>:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load('model.pth'))\n"
          ]
        }
      ]
    }
  ]
}